import streamlit as st
import pandas as pd
import plotly.graph_objects as go
import plotly.express as px
import sys
import os
from datetime import datetime

# Ajouter le chemin parent pour importer utils
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from utils.model_trainer import ModelTrainer

def show():
    st.title("ü§ñ R√©entra√Ænement des Mod√®les")
    st.markdown("### Entra√Æner ou r√©entra√Æner les mod√®les de Machine Learning")
    
    # Initialiser le trainer
    trainer = ModelTrainer()
    
    # V√©rifier si les donn√©es existent
    if not os.path.exists(trainer.DATA_FILE):
        st.error("‚ùå Fichier de donn√©es introuvable. Veuillez d'abord charger ou rafra√Æchir les donn√©es.")
        st.info(f"üìÅ Fichier attendu : {trainer.DATA_FILE}")
        return
    
    # Charger les m√©triques existantes si disponibles
    existing_metrics = trainer.load_metrics()
    
    # Afficher les performances actuelles des mod√®les
    st.markdown("---")
    st.markdown("#### üìä Performances actuelles des mod√®les")
    
    if existing_metrics:
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("##### üéØ Mod√®le de Classification (√âtiquette DPE)")
            if 'classification' in existing_metrics:
                classif = existing_metrics['classification']
                
                metric_col1, metric_col2 = st.columns(2)
                with metric_col1:
                    st.metric("Accuracy", f"{classif['accuracy']*100:.2f}%")
                with metric_col2:
                    st.metric("F1-Score", f"{classif['f1_score']:.3f}")
                
                st.info(f"üìÖ Entra√Æn√© le : {classif.get('trained_at', 'N/A')[:10]}")
                st.caption(f"√âchantillons d'entra√Ænement : {classif.get('train_samples', 'N/A'):,}")
            else:
                st.warning("Mod√®le non entra√Æn√©")
        
        with col2:
            st.markdown("##### üìà Mod√®le de R√©gression (Co√ªt Total)")
            if 'regression' in existing_metrics:
                regress = existing_metrics['regression']
                
                metric_col1, metric_col2 = st.columns(2)
                with metric_col1:
                    st.metric("R¬≤ Score", f"{regress['r2_score']:.3f}")
                with metric_col2:
                    st.metric("MAE", f"{regress['mae']:.2f} ‚Ç¨")
                
                st.info(f"üìÖ Entra√Æn√© le : {regress.get('trained_at', 'N/A')[:10]}")
                st.caption(f"√âchantillons d'entra√Ænement : {regress.get('train_samples', 'N/A'):,}")
            else:
                st.warning("Mod√®le non entra√Æn√©")
    else:
        st.info("‚ÑπÔ∏è Aucun mod√®le entra√Æn√© d√©tect√©. Lancez un premier entra√Ænement ci-dessous.")
    
    st.markdown("---")
    
    # Configuration de l'entra√Ænement
    st.markdown("#### ‚öôÔ∏è Configuration de l'entra√Ænement")
    
    col1, col2 = st.columns(2)
    
    with col1:
        test_size = st.slider(
            "Taille du jeu de test (%)",
            min_value=10,
            max_value=40,
            value=20,
            step=5,
            help="Pourcentage des donn√©es utilis√©es pour le test"
        )
    
    with col2:
        random_state = st.number_input(
            "Random State",
            min_value=0,
            max_value=100,
            value=42,
            help="Graine al√©atoire pour la reproductibilit√©"
        )
    
    # Param√®tres avanc√©s
    with st.expander("üîß Param√®tres avanc√©s des mod√®les"):
        col1, col2 = st.columns(2)
        
        with col1:
            n_estimators = st.number_input(
                "Nombre d'arbres",
                min_value=50,
                max_value=500,
                value=100,
                step=50,
                help="Nombre d'arbres dans la for√™t al√©atoire"
            )
            
            max_depth = st.number_input(
                "Profondeur maximale",
                min_value=5,
                max_value=50,
                value=20,
                step=5,
                help="Profondeur maximale des arbres"
            )
        
        with col2:
            min_samples_split = st.number_input(
                "Min √©chantillons pour split",
                min_value=2,
                max_value=20,
                value=5,
                help="Nombre minimum d'√©chantillons requis pour diviser un n≈ìud"
            )
            
            min_samples_leaf = st.number_input(
                "Min √©chantillons par feuille",
                min_value=1,
                max_value=10,
                value=2,
                help="Nombre minimum d'√©chantillons requis dans une feuille"
            )
    
    st.markdown("---")
    
    # Aper√ßu des donn√©es
    st.markdown("#### üëÄ Aper√ßu des donn√©es d'entra√Ænement")
    
    df_preview = pd.read_csv(trainer.DATA_FILE)
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("üìä Total enregistrements", f"{len(df_preview):,}")
    
    with col2:
        # Compter les valeurs non nulles pour les features
        valid_classif = df_preview[trainer.FEATURES + [trainer.TARGET_CLASSIFICATION]].dropna()
        st.metric("‚úÖ Valides (Classification)", f"{len(valid_classif):,}")
    
    with col3:
        valid_regress = df_preview[trainer.FEATURES + [trainer.TARGET_REGRESSION]].dropna()
        st.metric("‚úÖ Valides (R√©gression)", f"{len(valid_regress):,}")
    
    # Distribution des √©tiquettes DPE
    if trainer.TARGET_CLASSIFICATION in df_preview.columns:
        st.markdown("##### Distribution des √©tiquettes DPE")
        
        etiquette_counts = df_preview[trainer.TARGET_CLASSIFICATION].value_counts().sort_index()
        
        colors_dpe = {
            'A': '#00A550', 'B': '#52B153', 'C': '#C3D545',
            'D': '#FFF033', 'E': '#F39200', 'F': '#ED2124', 'G': '#CC0033'
        }
        
        fig = go.Figure(data=[
            go.Bar(
                x=etiquette_counts.index,
                y=etiquette_counts.values,
                marker_color=[colors_dpe.get(x, '#666') for x in etiquette_counts.index],
                text=etiquette_counts.values,
                textposition='outside'
            )
        ])
        
        fig.update_layout(
            xaxis_title="√âtiquette DPE",
            yaxis_title="Nombre",
            height=300,
            showlegend=False
        )
        
        st.plotly_chart(fig, use_container_width=True)
    
    st.markdown("---")
    
    # Bouton d'entra√Ænement
    if st.button("üöÄ Lancer l'entra√Ænement", type="primary", use_container_width=True):
        
        # Placeholder pour les messages de progression
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        try:
            # Pr√©parer les param√®tres du mod√®le
            model_params = {
                'n_estimators': n_estimators,
                'max_depth': max_depth,
                'min_samples_split': min_samples_split,
                'min_samples_leaf': min_samples_leaf,
                'random_state': random_state
            }
            
            # Callback de progression
            def update_status(message):
                status_text.info(message)
            
            # Charger les donn√©es
            update_status("üìÅ Chargement des donn√©es...")
            progress_bar.progress(0.1)
            
            df = pd.read_csv(trainer.DATA_FILE)
            
            # Pr√©parer les donn√©es
            update_status("üîß Pr√©paration des donn√©es...")
            progress_bar.progress(0.2)
            
            df_classif, df_regress = trainer.prepare_data(df)
            
            # Entra√Æner le mod√®le de classification
            update_status("üéØ Entra√Ænement du mod√®le de classification...")
            progress_bar.progress(0.3)
            
            classifier, classif_metrics = trainer.train_classification_model(
                df_classif,
                test_size=test_size/100,
                **model_params
            )
            
            progress_bar.progress(0.6)
            
            # Entra√Æner le mod√®le de r√©gression
            update_status("üìà Entra√Ænement du mod√®le de r√©gression...")

            regress_params = {
                k: v for k, v in model_params.items() if k != 'n_estimators'
                }
            
            regressor, regress_metrics = trainer.train_regression_model(
                df_regress,
                test_size=test_size/100,
                **regress_params
            )
            
            progress_bar.progress(0.9)
            
            # Sauvegarder les mod√®les
            update_status("üíæ Sauvegarde des mod√®les...")
            
            trainer.save_models(classifier, regressor)
            trainer.save_metrics({
                'classification': classif_metrics,
                'regression': regress_metrics
            })
            
            progress_bar.progress(1.0)
            status_text.success("‚úÖ Entra√Ænement termin√© avec succ√®s !")
            
            st.balloons()
            
            # Afficher les r√©sultats d√©taill√©s
            st.markdown("---")
            st.markdown("### üéâ R√©sultats de l'entra√Ænement")
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("#### üéØ Classification (√âtiquette DPE)")
                
                metric_col1, metric_col2, metric_col3 = st.columns(3)
                with metric_col1:
                    st.metric("Accuracy", f"{classif_metrics['accuracy']*100:.2f}%")
                with metric_col2:
                    st.metric("F1-Score", f"{classif_metrics['f1_score']:.3f}")
                with metric_col3:
                    st.metric("Classes", len(classif_metrics['classes']))
                
                st.caption(f"‚úÖ Entra√Æn√© sur {classif_metrics['train_samples']:,} √©chantillons")
                st.caption(f"üß™ Test√© sur {classif_metrics['test_samples']:,} √©chantillons")
                
                # Importance des features
                st.markdown("##### üìä Importance des features")
                feat_imp = pd.DataFrame({
                    'Feature': list(classif_metrics['feature_importance'].keys()),
                    'Importance': list(classif_metrics['feature_importance'].values())
                }).sort_values('Importance', ascending=False)
                
                fig_feat = px.bar(
                    feat_imp,
                    x='Importance',
                    y='Feature',
                    orientation='h',
                    color='Importance',
                    color_continuous_scale='Greens'
                )
                fig_feat.update_layout(height=400, showlegend=False)
                st.plotly_chart(fig_feat, use_container_width=True)
            
            with col2:
                st.markdown("#### üìà R√©gression (Co√ªt Total)")
                
                metric_col1, metric_col2, metric_col3 = st.columns(3)
                with metric_col1:
                    st.metric("R¬≤ Score", f"{regress_metrics['r2_score']:.3f}")
                with metric_col2:
                    st.metric("MAE", f"{regress_metrics['mae']:.0f} ‚Ç¨")
                with metric_col3:
                    st.metric("RMSE", f"{regress_metrics['rmse']:.0f} ‚Ç¨")
                
                st.caption(f"‚úÖ Entra√Æn√© sur {regress_metrics['train_samples']:,} √©chantillons")
                st.caption(f"üß™ Test√© sur {regress_metrics['test_samples']:,} √©chantillons")
                
                # Importance des features
                st.markdown("##### üìä Importance des features")
                feat_imp = pd.DataFrame({
                    'Feature': list(regress_metrics['feature_importance'].keys()),
                    'Importance': list(regress_metrics['feature_importance'].values())
                }).sort_values('Importance', ascending=False)
                
                fig_feat = px.bar(
                    feat_imp,
                    x='Importance',
                    y='Feature',
                    orientation='h',
                    color='Importance',
                    color_continuous_scale='Blues'
                )
                fig_feat.update_layout(height=400, showlegend=False)
                st.plotly_chart(fig_feat, use_container_width=True)
            
            # Rapport de classification d√©taill√©
            if 'classification_report' in classif_metrics:
                with st.expander("üìã Rapport de classification d√©taill√©"):
                    report_df = pd.DataFrame(classif_metrics['classification_report']).transpose()
                    st.dataframe(report_df.style.format("{:.3f}"), use_container_width=True)
        
        except Exception as e:
            status_text.error(f"‚ùå Erreur lors de l'entra√Ænement : {e}")
            st.exception(e)
    
    # Section d'information
    st.markdown("---")
    st.markdown("#### ‚ÑπÔ∏è Informations sur l'entra√Ænement")
    
    with st.expander("üìñ √Ä propos des mod√®les"):
        st.markdown("""
        **Mod√®le de Classification** :
        - Algorithme : Random Forest Classifier
        - Objectif : Pr√©dire l'√©tiquette DPE (A, B, C, D, E, F, G)
        - M√©trique principale : Accuracy et F1-Score
        
        **Mod√®le de R√©gression** :
        - Algorithme : Random Forest Regressor
        - Objectif : Pr√©dire le co√ªt total des 5 usages (‚Ç¨/an)
        - M√©triques principales : R¬≤, MAE, RMSE
        
        **Features utilis√©es** :
        """)
        st.code(", ".join(trainer.FEATURES))
        
        st.markdown("""
        **Pr√©traitement** :
        - Encodage des variables cat√©gorielles (type_batiment, type_energie_recodee)
        - Suppression des valeurs manquantes
        - S√©paration train/test avec stratification (classification)
        """)
    
    with st.expander("üí° Conseils pour l'entra√Ænement"):
        st.markdown("""
        **Quand r√©entra√Æner les mod√®les ?**
        - Apr√®s avoir rafra√Æchi les donn√©es avec de nouveaux DPE
        - Si les performances des mod√®les se d√©gradent
        - Pour exp√©rimenter avec diff√©rents hyperparam√®tres
        
        **Choix des hyperparam√®tres** :
        - **n_estimators** : Plus d'arbres = meilleure performance mais plus lent
        - **max_depth** : Contr√¥le la complexit√© (trop √©lev√© = surapprentissage)
        - **min_samples_split/leaf** : R√©gularisation pour √©viter le surapprentissage
        
        **Interpr√©tation des m√©triques** :
        - **Accuracy > 95%** : Excellent
        - **R¬≤ > 0.90** : Tr√®s bon pouvoir pr√©dictif
        - **MAE** : Erreur moyenne en euros (plus c'est bas, mieux c'est)
        """)

if __name__ == "__main__":
    show()